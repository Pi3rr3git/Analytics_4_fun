{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989d28a3",
   "metadata": {},
   "source": [
    "# ESt ce que le salaire des pilotes de F1 n est que base sur leur performances passes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9550de",
   "metadata": {},
   "source": [
    "### Problème : Peut-on deviner le salaire d'un pilote F1 basé sur ses stats ? (Poles, Victoires, Podiums, Points, etc.) (27/05/25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748ac81",
   "metadata": {},
   "source": [
    "### (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167abd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pierre-EmileMartin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\Pierre-EmileMartin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from io import StringIO\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f7ea2",
   "metadata": {},
   "source": [
    "# On a trouver un nouveau endroit pour chopper toutes les data.\n",
    "#### On commence part filtrer la tableau avec le nom des pilotes de la saison actuelle.\n",
    "#### On decide de garder la categorie starts, wins,poles , points et podiums pour realiser notre model de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0828fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      name  starts  wins  poles  points  podiums\n",
      "33         Alexander Albon     113     0      0   282.0        2\n",
      "51   Andrea Kimi Antonelli       9     0      0    48.0        0\n",
      "144           Carlos Sainz     215     4      6  1284.5       27\n",
      "150        Charles Leclerc     156     8     26  1524.0       46\n",
      "278           Esteban Ocon     165     1      0   465.0        4\n",
      "289        Fernando Alonso     410    32     22  2339.0      106\n",
      "295       Franco Colapinto      12     0      0     5.0        0\n",
      "312      Gabriel Bortoleto       9     0      0     0.0        0\n",
      "331         George Russell     137     3      6   825.0       19\n",
      "425           Isack Hadjar       8     0      0    21.0        0\n",
      "596           Lance Stroll     174     0      1   306.0        3\n",
      "597           Lando Norris     137     6     11  1183.0       34\n",
      "612         Lewis Hamilton     365   105    104  4933.5      202\n",
      "613            Liam Lawson      20     0      0    10.0        0\n",
      "673         Max Verstappen     218    65     43  3160.5      116\n",
      "719        Nico Hülkenberg     236     0      1   587.0        0\n",
      "734         Oliver Bearman      12     0      0    13.0        0\n",
      "745          Oscar Piastri      55     7      4   575.0       18\n",
      "810           Pierre Gasly     162     1      0   447.0        5\n",
      "992           Yuki Tsunoda      96     0      0   101.0        0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charge ta réponse JSON (par exemple si tu l'as dans un fichier 'response.json')\n",
    "with open('response.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraire la liste des records\n",
    "records = data['pageProps']['records']\n",
    "\n",
    "# Transformer en DataFrame pandas\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "\n",
    "df_active_drivers = df[df['active'] == True].copy()\n",
    "# print(df_active_drivers.head())\n",
    "\n",
    "\n",
    "colonnes_choisies = [\"name\",\"starts\", \"wins\",\"poles\", \"points\",\"podiums\"]       \n",
    "df_saison_25 = df_active_drivers[colonnes_choisies]\n",
    "print(df_saison_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4f813",
   "metadata": {},
   "source": [
    "#### Apres avoir chercher en ligne, nous avons la liste de pilotes et leur salaire pour la saison actuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ea572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name  starts  wins  poles  points  podiums  Base Salary (M $)\n",
      "0     Charles Leclerc     156     8     26  1524.0       46                 34\n",
      "1        Esteban Ocon     165     1      0   465.0        4                  5\n",
      "2     Fernando Alonso     410    32     22  2339.0      106                 20\n",
      "3   Gabriel Bortoleto       9     0      0     0.0        0                  2\n",
      "4      George Russell     137     3      6   825.0       19                 15\n",
      "5        Isack Hadjar       8     0      0    21.0        0                  1\n",
      "6        Lance Stroll     174     0      1   306.0        3                  3\n",
      "7        Lando Norris     137     6     11  1183.0       34                 20\n",
      "8      Lewis Hamilton     365   105    104  4933.5      202                 60\n",
      "9         Liam Lawson      20     0      0    10.0        0                  1\n",
      "10     Max Verstappen     218    65     43  3160.5      116                 65\n",
      "11     Oliver Bearman      12     0      0    13.0        0                  1\n",
      "12      Oscar Piastri      55     7      4   575.0       18                  6\n",
      "13       Pierre Gasly     162     1      0   447.0        5                 10\n",
      "14       Yuki Tsunoda      96     0      0   101.0        0                  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Salary = {\n",
    "    \"name\": [\"Max Verstappen\",\"Lewis Hamilton\",\"Charles Leclerc\",\"Fernando Alonso\",\"Lando Norris\",\"George Russell\",\"Carlos Sainz Jr.\",\"Pierre Gasly\",\"Alex Albon\",\n",
    "        \"Nico Hulkenberg\",\"Esteban Ocon\",\"Oscar Piastri\",\"Lance Stroll\",\"Gabriel Bortoleto\",\"Yuki Tsunoda\",\"Kimi Antonelli\",\"Oliver Bearman\",\"Liam Lawson\",\"Jack Doohan\",\"Isack Hadjar\"\n",
    "        ],\n",
    "    \"Base Salary (M $)\": [65,60,34,20,20,15,10,10,5,5,5,6,3,2,3,3,1,1,2,1]\n",
    "}\n",
    "df_base_salary = pd.DataFrame(Salary)\n",
    "saison_salary_25 = pd.merge(df_saison_25, df_base_salary, on=\"name\", how=\"inner\")\n",
    "print(saison_salary_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9e53f",
   "metadata": {},
   "source": [
    "#### On merge les deux data frame et on comment a entrainer le model. On seppare le data en un set de test et train pour entrainer notre model et le tester sur 20% du set entier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea93e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5628\n",
      "Test Loss (MSE): 1.56\n",
      "Actual: 5M, Predicted: 4.74M\n",
      "Actual: 3M, Predicted: 4.75M\n"
     ]
    }
   ],
   "source": [
    "# Séparer les variables\n",
    "X = saison_salary_25[['starts', 'wins', 'poles', 'points', 'podiums']]\n",
    "y = saison_salary_25['Base Salary (M $)']\n",
    "\n",
    "\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split en train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=46)\n",
    "\n",
    "# Création du modèle TensorFlow\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2 , verbose=0)\n",
    "\n",
    "# Évaluation\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss (MSE): {loss:.2f}\")\n",
    "\n",
    "# Prédiction sur X_test\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Actual: {y_test.values[i]}M, Predicted: {predictions[i][0]:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27060a1",
   "metadata": {},
   "source": [
    "### Interpreter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4044eb3",
   "metadata": {},
   "source": [
    "#### Apres avoir recuperer notre model je voudrais voir quelle est le poids de chaque categories et j aimerais voir si des insights interessant peuvent ressortir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e836490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starts: 0.1748\n",
      "wins: 0.1899\n",
      "poles: 0.1839\n",
      "points: 0.1619\n",
      "podiums: 0.1942\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# weights shape: (features, neurones)\n",
    "avg_importance_per_feature = np.mean(np.abs(weights), axis=1)\n",
    "\n",
    "# for i, importance in enumerate(avg_importance_per_feature):\n",
    "#     print(f\"Feature {i} importance moyenne absolue : {importance:.4f}\")\n",
    "\n",
    "features = ['starts', 'wins', 'poles', 'points', 'podiums']\n",
    "for feature, importance in zip(features, avg_importance_per_feature):\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13179c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
